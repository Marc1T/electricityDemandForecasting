{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modélisation Deep Learning — Prévision de la demande énergétique\n",
        "\n",
        "Ce notebook présente la démarche de modélisation avancée par réseaux de neurones (LSTM, GRU, CNN, CNN-LSTM) pour la prévision de la demande énergétique sur les données traitées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports et configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install python-dotenv tensorflow\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "os.chdir(\"..\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from src.models.dl_utils import create_sequences, scale_data\n",
        "from src.models.dl_models import build_lstm, build_gru, build_cnn, build_cnn_lstm\n",
        "from src.models.dl_training import train_and_save\n",
        "from src.models.evaluation import evaluate_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Chargement de la configuration et des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_config(config_path: str = \"config.yaml\") -> dict:\n",
        "    with open(config_path, \"r\") as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "    return cfg\n",
        "\n",
        "cfg = load_config(\"config.yaml\")\n",
        "processed_dir = Path(cfg[\"paths\"][\"data\"][\"processed\"])\n",
        "models_dir    = Path(\"models/dl\")\n",
        "models_dir.mkdir(exist_ok=True, parents=True)\n",
        "zones = [p.stem.replace(\"_processed_hourly\",\"\") for p in processed_dir.glob(\"*_processed_hourly.parquet\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Zones disponibles :\", zones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Définition des hyperparamètres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LOOKBACK = 24  # ex. 24 h\n",
        "HORIZON  = 1   # 1 pas à prévoir\n",
        "BATCH    = 32\n",
        "EPOCHS   = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Entraînement des modèles DL (LSTM, GRU, CNN, CNN-LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = []\n",
        "for zone in zones:\n",
        "    for horizon in [\"daily\", \"hourly\"]:\n",
        "        file = processed_dir/f\"{zone}_processed_{horizon}.parquet\"\n",
        "        if not file.exists():\n",
        "            print(f\"Fichier manquant pour {zone} {horizon}, passage...\")\n",
        "            continue\n",
        "        df = pd.read_parquet(file)\n",
        "        feature_cols = [c for c in df.columns if c != \"demand\"]\n",
        "        X, y = create_sequences(df, \"demand\", feature_cols, LOOKBACK, HORIZON)\n",
        "        split = int(len(X)*0.8)\n",
        "        X_train, X_val = X[:split], X[split:]\n",
        "        y_train, y_val = y[:split], y[split:]\n",
        "        X_train, X_val, scaler = scale_data(X_train, X_val)\n",
        "        input_shape = (LOOKBACK, len(feature_cols))\n",
        "        models = {\n",
        "            \"LSTM\":      build_lstm(input_shape, HORIZON),\n",
        "            \"GRU\":       build_gru(input_shape, HORIZON),\n",
        "            \"CNN\":       build_cnn(input_shape, HORIZON),\n",
        "            \"CNN-LSTM\":  build_cnn_lstm(input_shape, HORIZON)\n",
        "        }\n",
        "        for name, model in models.items():\n",
        "            print(f\"Training {name} for {zone} {horizon}...\")\n",
        "            hist, filepath = train_and_save(\n",
        "                model, X_train, y_train, X_val, y_val,\n",
        "                models_dir, zone, horizon, name,\n",
        "                epochs=EPOCHS, batch_size=BATCH\n",
        "            )\n",
        "            y_pred = model.predict(X_val)\n",
        "            y_val_flat = y_val.ravel()\n",
        "            y_pred_flat = y_pred.ravel()\n",
        "            score = evaluate_regression(None, None, pd.Series(y_val_flat), pd.Series(y_pred_flat))\n",
        "            metrics.append({\n",
        "                \"zone\": zone,\n",
        "                \"horizon\": horizon,\n",
        "                \"model\": name,\n",
        "                **score\n",
        "            })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sauvegarde et visualisation des métriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "metrics_df.to_csv(\"outputs/reports/all_zones_dl_metrics.csv\", index=False)\n",
        "display(metrics_df.head())\n",
        "metrics_df.groupby([\"zone\",\"horizon\",\"model\"])[[\"MAE\",\"RMSE\",\"MAPE\"]].mean().unstack().plot.bar(figsize=(12,6))\n",
        "plt.title(\"Comparaison des modèles DL par zone et horizon\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Résumé et prochaines étapes\n",
        "\n",
        "- Plusieurs architectures de réseaux de neurones ont été entraînées sur chaque zone et chaque horizon.\n",
        "- Les métriques (MAE, RMSE, MAPE) sont sauvegardées pour chaque modèle.\n",
        "- Les performances sont visualisées pour comparaison.\n",
        "- Prochaines étapes : tuning des hyperparamètres, modèles séquentiels avancés, intégration d’exogènes, analyse des résidus, etc."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
